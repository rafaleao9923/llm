{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Model Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Technical Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install bitsandbytes\n",
    "!pip install transformers\n",
    "!pip install accelerate\n",
    "!pip install diffusers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training a Neural Network model with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Prepare the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_list: [array([12, 31, 31, 61]), array([60, 16, 13, 50]), array([77, 32, 41, 92]), array([63, 23, 65, 24]), array([66, 17, 92, 81]), array([70, 41, 31, 27]), array([58, 38, 16, 12]), array([60, 47, 25,  2]), array([87, 51,  7, 26]), array([69, 49, 85, 74])]\n",
      "y_list: [668, 570, 1058, 623, 1118, 576, 378, 375, 537, 1143]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "w_list = np.array([2,3,4,7])\n",
    "\n",
    "import random\n",
    "x_list = []\n",
    "for _ in range(10):\n",
    "    x_sample = np.array([random.randint(1,100) for _ in range(len(w_list))])\n",
    "    x_list.append(x_sample)\n",
    "\n",
    "y_list = []\n",
    "for x_sample in x_list:\n",
    "    y_temp = x_sample@w_list\n",
    "    y_list.append(y_temp)\n",
    "\n",
    "print(\"x_list:\",x_list)\n",
    "print(\"y_list:\",y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Preparing for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w = nn.Parameter(torch.randn(len(w_list)))\n",
    "    \n",
    "    def forward(self, x:torch.Tensor):\n",
    "        return self.w @ x\n",
    "    \n",
    "model = MyLinear()\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.00001)\n",
    "\n",
    "x_input = torch.tensor(x_list, dtype=torch.float32)\n",
    "y_output = torch.tensor(y_list, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 201.5572\n",
      "Epoch [20/100], Loss: 10.8380\n",
      "Epoch [30/100], Loss: 3.5255\n",
      "Epoch [40/100], Loss: 1.7397\n",
      "Epoch [50/100], Loss: 0.9160\n",
      "Epoch [60/100], Loss: 0.4882\n",
      "Epoch [70/100], Loss: 0.2607\n",
      "Epoch [80/100], Loss: 0.1393\n",
      "Epoch [90/100], Loss: 0.0745\n",
      "Epoch [100/100], Loss: 0.0398\n",
      "train done\n"
     ]
    }
   ],
   "source": [
    "# start train model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for i, x in enumerate(x_input):\n",
    "        # forward\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = loss_fn(y_pred,y_output[i])\n",
    "\n",
    "        # zero out the cached parameter.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "\n",
    "        # update paramters\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "\n",
    "print(\"train done\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.9761, 3.0063, 4.0219, 6.9869], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training a model with Hugging Face Accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Training a model with Accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /home/andrewzhu/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n",
      "Epoch [10/100], Loss: 0.4956\n",
      "Epoch [20/100], Loss: 0.2719\n",
      "Epoch [30/100], Loss: 0.1492\n",
      "Epoch [40/100], Loss: 0.0818\n",
      "Epoch [50/100], Loss: 0.0449\n",
      "Epoch [60/100], Loss: 0.0246\n",
      "Epoch [70/100], Loss: 0.0135\n",
      "Epoch [80/100], Loss: 0.0074\n",
      "Epoch [90/100], Loss: 0.0041\n",
      "Epoch [100/100], Loss: 0.0022\n",
      "train done\n"
     ]
    }
   ],
   "source": [
    "# start train model using Accelerate\n",
    "from accelerate import utils\n",
    "utils.write_basic_config()\n",
    "\n",
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "\n",
    "x_input.to(device)\n",
    "y_output.to(device)\n",
    "model.to(device)\n",
    "\n",
    "model, optimizer = accelerator.prepare(\n",
    "    model, optimizer\n",
    ")\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for i, x in enumerate(x_input):\n",
    "        # forward\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = loss_fn(y_pred,y_output[i])\n",
    "\n",
    "        # zero out the cached parameter.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backward\n",
    "        #loss.backward()\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        # update paramters\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "print(\"train done\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([2.0359, 2.9466, 4.0035, 6.9901], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = accelerator.unwrap_model(model)\n",
    "model.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Prepare the training data for multiple GPUs training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "w_list = np.array([2,3,4,7])\n",
    "\n",
    "import random\n",
    "x_list = []\n",
    "for _ in range(10):\n",
    "    x_sample = np.array([random.randint(1,100) for _ in range(len(w_list))])\n",
    "    x_list.append(x_sample)\n",
    "\n",
    "y_list = []\n",
    "for x_sample in x_list:\n",
    "    y_temp = x_sample@w_list\n",
    "    y_list.append(y_temp)\n",
    "train_obj = {\n",
    "    'w_list':w_list.tolist()\n",
    "    , 'input':x_list\n",
    "    , 'output':y_list\n",
    "}\n",
    "\n",
    "import pickle\n",
    "with open('train_data.pkl','wb') as f:\n",
    "    pickle.dump(train_obj,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Train the model with multiple GPUs using Accelerate\n",
    "\n",
    "The code is in the file `train_model_in_2gpus.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd_venv_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
